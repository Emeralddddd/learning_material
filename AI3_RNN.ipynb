{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI3_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emeralddddd/learning_material/blob/master/AI3_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGn9UMePgkME",
        "colab_type": "code",
        "outputId": "2ab0f3af-9e84-4232-dbce-391ba4c673d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 332.1MB 56kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 28.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 419kB 40.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 22.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVi7HbkzgsLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NWQle2joE5P",
        "colab_type": "text"
      },
      "source": [
        "#数据预处理\n",
        "###读取文件\n",
        "经测试，原文件可以以txt的格式打开；由于原生编码为gbk，这里转换为utf-8读取；因为文本共1.5G，可能无法在小内存的设备上一次性处理；这种情况可以考虑使用tensorflowd的dataset等方式分步地读取数据\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vAmOzNCi6pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('news_sohusite_xml.smarty.txt',encoding='utf-8') as f:\n",
        "  str = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PP6xnsKorXs",
        "colab_type": "text"
      },
      "source": [
        "###提取信息\n",
        "由于原文本为标签文本，考虑到在文本分类中标题的内容与正文有很多重复，故这里只提取了正文部分做为特征，而使用url来作为标签；使用正则表达式可以很容易地提取到这两部分信息；分别提取后储存在dataframe中以备下一步的处理\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnewk8Jmpb7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "  with open(filename,encoding='utf-8') as f:\n",
        "    str = f.read()\n",
        "    \n",
        "  contentp = re.compile(r'<content>(.*?)</content>')\n",
        "  content = contentp.findall(str)\n",
        "  urlp = re.compile(r'<url>http://(.*?)/')\n",
        "  url = urlp.findall(str)\n",
        "  return pd.DataFrame({'content':content,'url':url})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMIC1ShDrMxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = load_data('news_sohusite_xml.smarty.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1tPR6r0pVQ6",
        "colab_type": "text"
      },
      "source": [
        "###文本清洗\n",
        "考虑到英文、数字、标点等可能会干扰文章内容，而本次实验计划采用基于字的神经网络，因此这里使用正则表达式去除了除汉字以外的所有文本内容，并且对字和标题分别进行了编码，对文本长度进行了填充对齐。返回了编码后的数据、标签和文本-编码转换的字典\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0OslrVprbi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(dataset):\n",
        "  cop = re.compile(\"[^\\u4e00-\\u9fa5]\")\n",
        "  \n",
        "  allcontent = cop.sub(\"\",str)\n",
        "  tmp = list(set([i for i in allcontent]))\n",
        "  dic = {tmp[i]:i for i in range(len(tmp))}\n",
        "  \n",
        "  dataset = dataset[dataset['content']!='']\n",
        "  dataset['content'] = dataset['content'].apply(lambda x:cop.sub(\"\",x))\n",
        "  values = []\n",
        "  for i in [j for j in dataset.values[:,0]]:\n",
        "    values.append([dic[j] for j in i])\n",
        "  values = np.array(list(map(lambda l:(l + [0]*(1000 - len(l)))[:1000], values)))\n",
        "  dicl = {i:index for index,i in enumerate(set(dataset['url'].values))}\n",
        "  labels = dataset['url'].apply(lambda x:dicl[x]).values\n",
        "  return values,labels,dic,dicl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEN6iuVmp7Wf",
        "colab_type": "code",
        "outputId": "c47aa018-7679-46eb-dd44-e93a3c263696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "values,labels,dic,dicl = preprocess(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1ewLxJMp7wq",
        "colab_type": "text"
      },
      "source": [
        "#\n",
        "###模型\n",
        "本次实验采用了单层的双向LSTM来对文本进行处理；\n",
        "实现方式采用了keras的顺序结构模型，分别使用了一个嵌入层、一个LSTM层、一个全连接层和一个输出层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peChWabrtBN3",
        "colab_type": "code",
        "outputId": "287648f0-480f-41c1-e8b8-bee16bfc01db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(2469, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0605 09:33:41.401958 140515976701824 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fcbfe61d0b8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "W0605 09:33:41.411154 140515976701824 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fcbfe61d748>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2PkNDxkqhg3",
        "colab_type": "text"
      },
      "source": [
        "###误差函数\n",
        "采用了交叉熵作为误差函数\n",
        "###优化算法\n",
        "采用了adam优化算法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyBzANmNtCXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DZtqvgyt6mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.output_shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9L0ZmdXuIVx",
        "colab_type": "code",
        "outputId": "b6bcd913-e99a-4555-d555-460c2f09922a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(values,labels,validation_freq=0.3,batch_size=32,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "164/164 [==============================] - 2s 9ms/sample - loss: 0.1653 - accuracy: 0.9268\n",
            "Epoch 2/10\n",
            "164/164 [==============================] - 1s 8ms/sample - loss: 0.1365 - accuracy: 0.9512\n",
            "Epoch 3/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.1228 - accuracy: 0.9573\n",
            "Epoch 4/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.0948 - accuracy: 0.9573\n",
            "Epoch 5/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.0858 - accuracy: 0.9573\n",
            "Epoch 6/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.0853 - accuracy: 0.9573\n",
            "Epoch 7/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.0821 - accuracy: 0.9573\n",
            "Epoch 8/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.0829 - accuracy: 0.9512\n",
            "Epoch 9/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.0820 - accuracy: 0.9512\n",
            "Epoch 10/10\n",
            "164/164 [==============================] - 1s 7ms/sample - loss: 0.0804 - accuracy: 0.9512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcbdba82da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7u8dyklCQ9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}